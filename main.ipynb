{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f823ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from importlib import reload\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b15380",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff67f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = list(pickle.load(open('data/alphabet.pkl', 'rb')))\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53443a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.audio\n",
    "reload(src.audio)\n",
    "import src\n",
    "reload(src)\n",
    "from src import TextProcessor, AudioProcessor\n",
    "\n",
    "text_processor = TextProcessor(alphabet)\n",
    "audio_processor = AudioProcessor(\n",
    "    sr=22050, ref_level_db=20, n_fft=2048, n_mels=80, hop_length=1024, window='hann'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849910e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 4907 samples with a total of 19.0 hours audio.\n",
      "Validation data has 1231 samples with a total of 5.0 hours audio.\n"
     ]
    }
   ],
   "source": [
    "import src.data\n",
    "reload(src.data)\n",
    "import src\n",
    "reload(src)\n",
    "from src import TTSDataset, get_dataloader\n",
    "\n",
    "\n",
    "# mel_path = '/media/data/soroosh/dataset/tts/persian-tts/mels/'\n",
    "\n",
    "train_ds = TTSDataset(\n",
    "    'data/persian-tts-train.json', \n",
    "#     'data/train.json',\n",
    "    audio_processor, text_processor, \n",
    "    div_steps=1, \n",
    "    use_phonemes=False, \n",
    "    precompute_mels=False, \n",
    "#     mel_path=mel_path, \n",
    ")\n",
    "val_ds = TTSDataset(\n",
    "    'data/persian-tts-test.json', \n",
    "#     'data/val.json',\n",
    "    audio_processor, text_processor, \n",
    "    div_steps=1, \n",
    "    use_phonemes=False, \n",
    "    precompute_mels=False, \n",
    "#     mel_path=mel_path, \n",
    ")\n",
    "print(f'Training data has {len(train_ds)} samples with a total of {train_ds.meta.duration.sum() // 3600} hours audio.')\n",
    "print(f'Validation data has {len(val_ds)} samples with a total of {val_ds.meta.duration.sum() // 3600} hours audio.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623ac0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = get_dataloader(train_ds, batch_size=6, n_jobs=6)\n",
    "vl = get_dataloader(val_ds, batch_size=6, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1452555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 409]) torch.int64\n",
      "torch.Size([6]) torch.int64\n",
      "torch.Size([6, 1042, 80]) torch.float32\n",
      "torch.Size([6]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(vl))\n",
    "for a in b:\n",
    "    print(a.shape, a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de7a10",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cc168b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': {'n_vocab': 36,\n",
       "  'd_emb': 256,\n",
       "  'd_hidden': 256,\n",
       "  'n_head': 8,\n",
       "  'd_inner': 512,\n",
       "  'n_encoder_layers': 4,\n",
       "  'n_prenet_layers': 3,\n",
       "  'kernel': 5,\n",
       "  'dropout': 0.2},\n",
       " 'decoder': {'n_mel': 80,\n",
       "  'd_hidden': 256,\n",
       "  'n_head': 8,\n",
       "  'd_inner': 512,\n",
       "  'outputs_per_step': 1,\n",
       "  'n_decoder_layers': 4,\n",
       "  'n_postnet_layers': 5,\n",
       "  'kernel': 5,\n",
       "  'dropout': 0.2},\n",
       " 'lr': 0.001,\n",
       " 'max_epochs': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'encoder': {\n",
    "        'n_vocab' : text_processor.n_vocab,\n",
    "        'd_emb' : 256, \n",
    "        'd_hidden' : 256, \n",
    "        'n_head' : 8, \n",
    "        'd_inner' : 512, \n",
    "        'n_encoder_layers' : 4, \n",
    "        'n_prenet_layers' : 3, \n",
    "        'kernel' : 5, \n",
    "        'dropout' : 0.2\n",
    "    },\n",
    "    'decoder': {\n",
    "        'n_mel' : 80, \n",
    "        'd_hidden' : 256, \n",
    "        'n_head' : 8, \n",
    "        'd_inner' : 512, \n",
    "        'outputs_per_step' : 1,\n",
    "        'n_decoder_layers' : 4, \n",
    "        'n_postnet_layers' : 5, \n",
    "        'kernel' : 5, \n",
    "        'dropout' : 0.2\n",
    "    },\n",
    "    'lr' : 1e-3,\n",
    "    'max_epochs' : 100\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efb46cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7782564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.modules\n",
    "reload(src.modules)\n",
    "import src.model\n",
    "reload(src.model)\n",
    "import src\n",
    "reload(src)\n",
    "from src import TransformerTTS\n",
    "\n",
    "model = TransformerTTS(config, audio_processor, text_processor)\n",
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba14de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3654, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.step(b, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007decb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = model.make_attn_figure(attn[0])\n",
    "# fig = model.make_spec_figure(linear_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae0b14",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8f297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# logger = TensorBoardLogger(save_dir='logs/', name='persian-tts-l1-l2')\n",
    "# lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     dirpath='weights/persian-tts/', \n",
    "#     filename='{epoch}-{val_loss:.2f}', \n",
    "#     monitor='train_loss',\n",
    "#     save_top_k=5, \n",
    "#     period=1\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=8,\n",
    "    logger=logger, \n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9ef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | l1      | L1Loss           | 0     \n",
      "1 | l2      | MSELoss          | 0     \n",
      "2 | ce      | CrossEntropyLoss | 0     \n",
      "3 | encoder | Encoder          | 3.2 M \n",
      "4 | decoder | Decoder          | 4.6 M \n",
      "---------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.130    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f0cbb764dd416691831c671b94d14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa37007",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('weights/persian-tts/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0ce29",
   "metadata": {},
   "source": [
    "## synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model\n",
    "reload(src.model)\n",
    "import src\n",
    "reload(src)\n",
    "from src import TransformerTTS\n",
    "\n",
    "gen_model = TransformerTTS.load_from_checkpoint('weights/persian-tts/last.ckpt', config=config, audio_processor=audio_processor, text_processor=text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'خدایا'\n",
    "mel, post = gen_model.synthesize(text, max_len=30)\n",
    "mel.shape, post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mel.T, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = audio_processor.mel_to_audio(mel.detach().cpu().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "Audio(y, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder = torch.hub.load('seungwonpark/melgan', 'melgan')\n",
    "vocoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_denorm = audio_processor.denormalize(mel.detach().cpu().numpy().T)\n",
    "mel_denorm = librosa.db_to_power(mel_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_denorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = vocoder.inference(torch.tensor(mel_denorm).unsqueeze(0))\n",
    "print(audio.shape)\n",
    "plt.plot(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
